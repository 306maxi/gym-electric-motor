{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEM Cookbook\n",
    "\n",
    "This notebook aims to provide an introduction to the usage of the gym-electric-motor (GEM) toolbox. The first section deals with the basic building blocks of GEM.\n",
    "Further sections provide a step by step guide to customize the different features offered by the toolbox. In this example, a guide to create a customized discrete permanent magnet synchronous motor (PMSM) environment is presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.    Overview\n",
    "\n",
    "The gym-electric-motor (GEM) package is a Python toolbox for the simulation and control of various electric motors.\n",
    "\n",
    "It is built upon [OpenAI Gym Environments](https://gym.openai.com/), and, therefore, can be used for both, classical control simulation and reinforcement learning experiments. It allows you to construct a typical drive train with the usual building blocks, i.e. supply voltages, converters, electric motors and load models, and obtain not only a closed-loop simulation of this physical structure, but also a rich interface for plugging in any decision making algorithm, from PI-controllers to [Deep Deterministic Policy Gradient](https://spinningup.openai.com/en/latest/algorithms/ddpg.html) agents.\n",
    "\n",
    "### 1.1  Installation\n",
    "Before you can start, you need to make sure that you have gym-electric-motor installed. You can install it easily using pip:\n",
    "\n",
    "```\n",
    "pip install gym-electric-motor\n",
    "```\n",
    "    \n",
    "Alternatively, install the latest developer version directly from GitHub:\n",
    "https://github.com/upb-lea/gym-electric-motor\n",
    "\n",
    "For this notebook, we can install it by executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/upb-lea/gym-electric-motor.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Building Blocks\n",
    "A GEM environment consists of following building blocks:\n",
    "- Physical Structure:\n",
    "   - Supply Voltage\n",
    "   - Converter\n",
    "   - Electric motor\n",
    "   - Load Model\n",
    "- Utility functions for reference generation, reward calculation and visualization\n",
    " \n",
    "#### Information Flow in a GEM Environment\n",
    "![](../../docs/plots/SCML_Overview.svg)\n",
    "\n",
    "The following motor models are included:\n",
    "\n",
    "Four DC motors:\n",
    "\n",
    "- permanently excited motor\n",
    "- externally excited motor\n",
    "- series motor\n",
    "- shunt motor\n",
    "\n",
    "Two three phase motors:\n",
    "\n",
    "- PMSM (permanent magnet synchronous motor)\n",
    "- SynRM (synchronous reluctance motor)\n",
    "\n",
    "Two variants of the induction motor:\n",
    "\n",
    "- SCIM (squirrel cage induction motor)\n",
    "- DFIM (doubly fed induction motor)\n",
    "\n",
    "Following converters are included:\n",
    "\n",
    "- 1 quadrant converter (1QC)\n",
    "\n",
    "- 2 quadrant converter (2QC) as an asymmetric half bridge with both current polarities\n",
    "\n",
    "- 4 quadrant converter (4QC)\n",
    "\n",
    "- B6 Bridge Converter (B6C)\n",
    "\n",
    "All converters can consider interlocking times and a dead time of one sampling interval.\n",
    "Furthermore, they can be controlled with a discrete action space or a continuous action space.\n",
    "\n",
    "Discrete actions are the direct switching states of the transistors.\n",
    "Continuous actions are the duty cycles for a pulse width modulation on the transistors. \n",
    "\n",
    "The load model consists of a quadratic load function, with user defined coefficients. \n",
    "Furthermore the moment of inertia of the load attached to the motor can be specified.\n",
    "\n",
    "The included states for each motor are summarized and briefly described in the [Motor Dashboard](visualizations/motor_dashboard.html).\n",
    "Every state that can be plotted can also be used in the state filter or as observed state.\n",
    "The actions are basically understood as the desired duty cycles. The actual applied voltage can be taken from the observations.\n",
    "The observations are normalized to their physical limits that can be accessed with `env.limits`.\n",
    "Therefore, all values are typically in a range of [0, 1] or [-1, 1] without limit violation.\n",
    "\n",
    "All nominal values of voltages and currents are DC values in the case of a DC motor and peak phase values for the PMSM.\n",
    "Therefore, data sheet values for line voltage and phase currents of a PMSM has to be transformed with:\n",
    "$U_N = \\sqrt{\\frac{2}{3}}U_L$, $I_N = \\sqrt{2}I_S$.\n",
    "\n",
    "Moreover, the angular velocity is the mechanical one and not the electrical:\n",
    "$p\\omega_me = p\\omega = \\omega_el$\n",
    "\n",
    "### 1.3 OpenAI Gym Interface\n",
    "Like every gym environment, the basic user interface consists of four main functions.\n",
    "* `import gym_electric_motor as gem`    \n",
    "   Import the package. \n",
    "\n",
    "* `env = gem.make(environment-id, **kwargs)`  \n",
    "    Returns an instantiated motor environment. Call this function at the beginning.\n",
    "    The `gem.make()` method is equal to the `gym.make()`. By using `gem.make()`you can avoid importing gym additionally. \n",
    " \n",
    "* `(initial_state, initial_reference) = env.reset()`  \n",
    "    Resets the motor. This includes a new initial state and new reference trajectories.\n",
    "    Call this function before a new episode starts. \n",
    "\n",
    "* `(state, reference), reward, done, _ = env.step(action)`      \n",
    "    This function performs one action on the environment for one time step.\n",
    "    It simulates the motor and needs to be called in every time step.\n",
    "    First, the voltage applied on the motor due to the converter output is determined and then an ODE solver is used to compute the next state. \n",
    "    Eventually, the reward is evaluated and returned together with the next observation and a flag indicating termination.\n",
    "    Several reward functions are available.\n",
    "\n",
    "* `env.render()`    \n",
    "    Update the visualization of the motor states.\n",
    "    The signals to be displayed may be specified in the constructor-parameters of ```gem.make(**kwargs)```.\n",
    "    All visualizations are optional and should be disabled for increased computing speed.\n",
    "\n",
    "Basic Routine:\n",
    "\n",
    "```py\n",
    "import gym_electric_motor as gem\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = gem.make(\"PMSMDisc-v1\")  # instantiate a discretely controlled PMSM\n",
    "    env.reset()\n",
    "    for _ in range(1000):\n",
    "        env.render()  # visualize environment\n",
    "        (states, references), rewards, done, _ = env.step(env.action_space.sample())  # pick random control actions\n",
    "    env.close()\n",
    "```\n",
    "\n",
    "### 1.4 Environment Ids\n",
    "\n",
    "* DC Motors\n",
    "\n",
    "    * `'DcExtExCont-v1'`\n",
    "        Externally excited DC motor with continuous actions.\n",
    "     \n",
    "    * `'DcExtExDisc-v1'`\n",
    "        Externally excited DC motor with discrete actions.\n",
    "    \n",
    "    * `'DcPermExCont-v1'`\n",
    "        Permanently excited DC motor with continuous actions.\n",
    "    \n",
    "    * `'DcPermexDisc-v1'`\n",
    "        Permanently excited DC motor with discrete actions.\n",
    "    \n",
    "    * `'DcShuntCont-v1'`\n",
    "        DC shunt motor with continuous actions.\n",
    "    \n",
    "    * `'DcShuntDisc-v1'`\n",
    "        DC shunt motor with discrete actions.\n",
    "    \n",
    "    * `'DcSeriesCont-v1'`\n",
    "        DC series motor with continuous actions.\n",
    "    \n",
    "    * `'DcSeriesDisc-v1'`\n",
    "        DC series motor with discrete actions.\n",
    "        \n",
    "* Synchronous Motors\n",
    "    \n",
    "    * `'PMSMCont-v1'`:  \n",
    "        Permanent magnet synchronous motor with continuous actions.\n",
    "    \n",
    "    * `'PMSMDisc-v1'`:  \n",
    "        Permanent magnet synchronous motor with discrete actions.\n",
    "        \n",
    "    * `'SynRMCont-v1'`:  \n",
    "        Synchronous reluctance motor with continuous actions.\n",
    "    \n",
    "    * `'SynRMDisc-v1'`:  \n",
    "        Synchronous reluctance motor with discrete actions.\n",
    "        \n",
    "* Induction Motors\n",
    "\n",
    "    * `'SCIMCont-v1'`:  \n",
    "        Squirrel cage induction motor with continuous actions.\n",
    "        \n",
    "    * `'SCIMDisc-v1'`:  \n",
    "        Squirrel cage induction motor with discrete actions.\n",
    "        \n",
    "    * `'DFIMCont-v1'`:  \n",
    "        Doubly fed induction motor with continuous actions.\n",
    "        \n",
    "    * `'DFIMDisc-v1'`:  \n",
    "        Doubly fed induction motor with discrete actions.\n",
    "\n",
    "\n",
    "\n",
    "### 1.5 Make keyword arguments\n",
    "Using the keyword arguments in the `gem.make(id, **kwargs)` function you can select different function modules for the \n",
    "environment and parametrize these modules. \n",
    "The main level modules of each GEM-environment consists of four function modules:\n",
    "\n",
    "* Physical System\n",
    "    * keyword: `physical_system`\n",
    "    * Specification and simulation of the system model.\n",
    "* Reference Generator\n",
    "    * keyword: `reference_generator`\n",
    "    * Generation of references that the physical system has to follow.\n",
    "* Reward Function\n",
    "    * keyword: `reward_function`\n",
    "    * Reward calculation based on the current state and reference.\n",
    "* Visualization    \n",
    "    * keyword: `visualization`\n",
    "    * Visualization of the physical systems state, reference and rewards.\n",
    "* State Filter\n",
    "    * keyword: `state_filter`\n",
    "    * Selection of states that shall be shown to the agent.\n",
    "    \n",
    "These function modules can be selected in three ways:\n",
    "\n",
    "* Passing a keystring (and further keyword arguments for the class) :\n",
    "     * `reference_generator='SinusoidalReference', amplitude_range=(0.2, 0.8)`\n",
    "\n",
    "* Passing a class pointer (and further keyword arguments for the class)\n",
    "    * `reference_generator=SinusoidalReferenceGenerator, amplitude_range=(0.2,0.8)`\n",
    "\n",
    "* Passing an instantiated object\n",
    "  * `reference_generator = SinusoidalReferenceGenerator(amplitude_range=(0.2,0.8)`\n",
    "      \n",
    "Furthermore, the internal function modules of the physical systems like the converter, motor, or load can be selected in\n",
    "the make keyword-arguments in the same way. \n",
    "\n",
    "The available modules and specific keyword-arguments for each module can be looked up in the [API documentation](https://upb-lea.github.io/gym-electric-motor/parts/environments/environment.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Customize a PMSM Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic PMSM environment\n",
    "The following cell provides a method to create a basic motor environment. \n",
    "By simply calling the ```gem.make()``` function with the motor environment ID of the required electric motor, one can create a basic motor environment with default parameters and settings for all the relevant sub-components.\n",
    "\n",
    "With the environment ID you select a certain motor type and action type (continuous or discrete) and with the further \n",
    "constructor arguments you can parametrize the environment to your control problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gym_electric_motor.envs.gym_pmsm.perm_mag_syn_motor_env.DiscPermanentMagnetSynchronousMotorEnvironment at 0x7f531eadd5d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym_electric_motor as gem\n",
    "\n",
    "basic_env = gem.make(\"PMSMDisc-v1\")  # pass a motor environment ID \n",
    "basic_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2  Physical System\n",
    "Each system consists of a voltage supply, a power electronic converter, an electrical motor, and the mechanical load (SCML) as shown in the above figure. Each such SCML-system is simulated by a user-defined ODE solver.\n",
    "\n",
    "#### Voltage Supply\n",
    "\n",
    "The voltage supply module provides both, DC and AC voltage supplies. \n",
    "- The DC supplies are either ideal or non-ideal voltage sources.\n",
    "- The AC supplies are either ideal single phase or ideal three-phase AC sources.\n",
    "\n",
    "More documentation regarding the voltage supplies of GEM can be found [here](https://upb-lea.github.io/gym-electric-motor/parts/physical_systems/voltage_supplies/voltage_supply.html). \n",
    "For the PMSM environment example, a non-ideal DC voltage supply is created. \n",
    "Here, the DC-link is modeled as an RC-circuit loaded from an ideal DC voltage source. \n",
    "\n",
    "The non-ideal DC supply in GEM is named 'RCVoltageSupply' and the supply_parameter(dict) consists of resistance R in ohm and capacitance C in farad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "supply = 'RCVoltageSupply'\n",
    "supply_parameter=dict(R=10, C=4e-3)  # Note, R and C values here are not realistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converter \n",
    "The converters are divided into two classes: The continuously controlled and the discretely controlled converters.\n",
    "\n",
    "In the continuous case, the agent's actions denote a duty cycle that is modulated to the converter's output voltage.\n",
    "\n",
    "In the discrete case, the agent's actions denote switching states of the converter at the given instant.\n",
    "Here, only a discrete amount of options are available. In this notebook, for the PMSM the discrete B6 bridge converter with six switches is utilized per default. This converter provides a total of eight possible actions.\n",
    "![](../../docs/plots/B6.svg)\n",
    "\n",
    "\n",
    "#### Motor \n",
    "In this tutorial, the electric motor used is the **Permanent Magnet Synchronous Motor**.\n",
    "The motor schematic is the following:\n",
    "\n",
    "\n",
    "![](../../docs/plots/ESBdq.svg)\n",
    "\n",
    "And the electrical ODEs for that motor are:\n",
    "\n",
    "<h3 align=\"center\">\n",
    "\n",
    "<!-- $\\frac{\\mathrm{d}i_{sq}}{\\mathrm{d}t} = \\frac{u_{sq}-pL_d\\omega_{me}i_{sd}-R_si_{sq}}{L_q}$\n",
    "\n",
    "$\\frac{\\mathrm{d}i_{sd}}{\\mathrm{d}t} = \\frac{u_{sd}-pL_q\\omega_{me}i_{sq}-R_si_{sd}}{L_d}$\n",
    "\n",
    "$\\frac{\\mathrm{d}\\epsilon_{el}}{\\mathrm{d}t} = p\\omega_{me}$\n",
    " -->\n",
    "\n",
    "   $ \\frac{\\mathrm{d}i_{sd}}{\\mathrm{d}t}=\\frac{u_{sd} + p\\omega_{me}L_q i_{sq} - R_s i_{sd}}{L_d} $ <br><br>\n",
    "    $\\frac{\\mathrm{d} i_{sq}}{\\mathrm{d} t}=\\frac{u_{sq} - p \\omega_{me} (L_d i_{sd} + \\mathit{\\Psi}_p) - R_s i_{sq}}{L_q}$ <br><br>\n",
    "   $\\frac{\\mathrm{d}\\epsilon_{el}}{\\mathrm{d}t} = p\\omega_{me}$\n",
    "\n",
    "</h3>\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "The motor environment ID for the discrete PMSM motor is **\"PMSMDisc-v1\"**.\n",
    "The parameters of the specific motor are to be passed by the user as a motor parameter dictionary.\n",
    "Default parameters will be considered in case the motor parameters are not provided by the user. \n",
    "The nominal and limit values which define the operating region of the motor are also passed as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_env_id = \"PMSMDisc-v1\"\n",
    "tau = 1e-5    # The duration of each sampling step\n",
    "motor_parameter = dict(p=3,  # [p] = 1, nb of pole pairs\n",
    "                       r_s=17.932e-3,  # [r_s] = Ohm, stator resistance\n",
    "                       l_d=0.37e-3,  # [l_d] = H, d-axis inductance\n",
    "                       l_q=1.2e-3,  # [l_q] = H, q-axis inductance\n",
    "                       psi_p=65.65e-3,  # [psi_p] = Vs, magnetic flux of the permanent magnet\n",
    "                       )  # BRUSA\n",
    "\n",
    "nominal_values=dict(omega=4000*2*np.pi/60,  # angular velocity in rpm\n",
    "                    i=230,                  # motor current in amps\n",
    "                    u=350                   # nominal voltage in volts\n",
    "                    )\n",
    "# limit values are taken exemplarily as 1.3 times the nominal values\n",
    "limit_values = {key: 1.5 * nomin for key, nomin in nominal_values.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motor state initializer\n",
    "By default, the motor states (e.g. motor currents, rotational speed) are always set to zero whenever the motor environment is reset. In order to generate diverse expisodes, the motor state initializer can be used to draw the initial state values from a given probability distribution within the nominal operating range of the given motor. \n",
    "\n",
    "The 'motor_initializer' is a dictionary that consists of the type of distribution, for example, uniform or gaussian distribution and the interval of values within the nominal operating region. \n",
    "Here, the motor states, i.e. $i_{sd}$, $i_{sq}$ and motor angle are initialized with values sampled from a uniform distribution from the provided intervals.\n",
    "\n",
    "$i_{sd}$ and $i_{sq}$ are the motor currents in the [d-q coordinate system](https://en.wikipedia.org/wiki/Direct-quadrature-zero_transformation#:~:text=The%20direct%2Dquadrature%2Dzero%20,an%20effort%20to%20simplify%20analysis).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "motor_initializer={'random_init': 'uniform', 'interval': [[-230, 230], [-230, 230], [-np.pi, np.pi]]}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mechanical Load\n",
    "The mechanical load module in GEM models various external mechanical systems that apply counterforces on the electrical motor's rotor through the drive shaft.\n",
    "Different types of load models such as constant speed load and polynomial static load are provided. More information can be found in the [documentation.](https://upb-lea.github.io/gym-electric-motor/parts/physical_systems/mechanical_loads/mechanical_load.html)\n",
    "\n",
    "In this example, the load type: _ConstSpeedLoad_ is used. \n",
    "This initializes the load with a constant speed at the start of each episode. \n",
    "The initialization value for speed is sampled from a uniform distribution defined by the given interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_electric_motor.physical_systems import ConstantSpeedLoad\n",
    "\n",
    "load = 'ConstSpeedLoad'\n",
    "load_initializer={'random_init': 'uniform', 'interval':[100,200] }   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Reward Function\n",
    "The reward calculation is based on the current state and reference of the motor environment. It is calculated as a weighted sum of errors with a certain power as follows:\n",
    "\n",
    "<!-- <h3 align=\"center\"> -->\n",
    "<!-- $ reward = - reward\\_weights * (abs(state - reference)/ state\\_length)^{reward\\_power}$   -->\n",
    "\n",
    "$ r_t = - \\sum \\limits_{k=0} ^{N} w_{\\{k\\}}\\big | s_{\\{k\\}t} - s^*_{\\{k\\}t} \\big |^p $   <br> <br>\n",
    "\n",
    "Here, $r_t$ is the reward at time $t$.  $ w_{\\{k\\}}$ is the reward weight for the k'th state variable of the $N$ referenced states . $s_{\\{k\\}t}$ is the k'th state variable of the motor and $s^*_{\\{k\\}t}$ is the corresponding k'th reference variable at time $t$. The reward power is $p$.\n",
    "\n",
    "\n",
    "If states are to be monitored for a constraint violation, an additional terminal reward is added. This value depends on the discount factor $\\gamma$ as follows. \n",
    "<!-- <h3 align=\"center\"> -->\n",
    "$r_t = -1 / (1 - \\gamma).$\n",
    "\n",
    "\n",
    "### 2.4 Constraint Monitor\n",
    "The constraint monitor monitors the system states and assesses whether they comply with the given limits or violate them. \n",
    "It provides any necessary information to the reward function.\n",
    "The constraints of the system states can be generally described by the user, and by default is restricted by the physical enviroment limits.\n",
    "\n",
    "The user defined constraint: \"SqdCurrentMonitor\" presented below, monitors the currents and raises a flag indicating a limit violation if :\n",
    "\n",
    "$ i_{sd}^2 + i_{sq}^2 > i_{max}^2 $  \n",
    "Here $i_{sd}$ and $i_{sq}$ are the motor currents in the d-q coordinate system that can be accessed from the motor states and $i_{max}$ is the maximum allowable current value.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gamma = 0.99  #Discount factor for the reward punishment. Should equal agents' discount factor gamma.\n",
    "\n",
    "def monitor_sqd_currents(state, observed_states, k, physical_system):\n",
    "    \"\"\"\n",
    "    monitor for squared currents:\n",
    "\n",
    "    i_sd**2 + i_sq**2 < nominal_limit\n",
    "    \"\"\"\n",
    "    I_SD_IDX = physical_system.state_names.index('i_sd') # access motor state i_sd\n",
    "    I_SQ_IDX = physical_system.state_names.index('i_sq') # access motor state i_sq\n",
    "    sqd_currents = state[I_SD_IDX] ** 2 + state[I_SQ_IDX] ** 2\n",
    "    return sqd_currents > 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Reference Generator\n",
    "The reference generator produces reference trajectories for the observed states, that the physical system is expected to follow. \n",
    "The GEM toolbox provides various reference generators, which can be found in the [documentation.](https://upb-lea.github.io/gym-electric-motor/parts/reference_generators/reference_generator.html)\n",
    "\n",
    "In this example, references to the motor currents $i_{sq}$ and $i_{sd}$ are considered.\n",
    "The \"WienerProcessReferenceGenerator\" is used to generate random references for both $i_{sq}$ and $i_{sd}$. \n",
    "\n",
    "The [Wiener process](https://en.wikipedia.org/wiki/Wiener_process) is a stochastic process $W(t)$ for $t>=0$ with $W(0)=0$ such that the increment $W(t)-W(s)$ is Gaussian with mean $0$ and variance $\\sigma$ for any $0<=s<t$, while increments for successive time steps are statistically independent.\n",
    "\n",
    "The individual sub-reference generators are then combined using the \"MultipleReferenceGenerator\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_electric_motor.reference_generators import \\\n",
    "    MultipleReferenceGenerator,\\\n",
    "    WienerProcessReferenceGenerator\n",
    "\n",
    "q_generator = WienerProcessReferenceGenerator(reference_state='i_sq') # sub-reference generator for i_sq\n",
    "d_generator = WienerProcessReferenceGenerator(reference_state='i_sd') # sub-reference generator for i_sd\n",
    "rg = MultipleReferenceGenerator([q_generator, d_generator])           # combine the sub-reference generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Visualization\n",
    "The visualization module provides an interface to observe and inspect the physical system's states, references, rewards, etc. \n",
    "GEM offers two forms of visualization:\n",
    "- Motor dashboard: A graphical interface which provides visualization in the form of plots.\n",
    "- Console printer: A simpler interface in the form of console print-outs.\n",
    "\n",
    "This example demonstrates the usage of the motor dashboard for visualization.\n",
    "A list of variables to be plotted is passed to the MotorDashboard during initialization. The variables that can be plotted for a given motor environment can be found in the [documentation.](https://upb-lea.github.io/gym-electric-motor/parts/visualizations/motor_dashboard.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_electric_motor.visualization import MotorDashboard\n",
    "\n",
    "visualization = MotorDashboard(plots=['i_sq', 'i_sd', 'reward']) # plots the states i_sd and i_sq and reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Callbacks\n",
    "GEM callbacks provide an easy-to-use interface to apply hooks on the motor environment during run time. \n",
    "Callbacks can be used to get a view of the internal states, collect statistics, or modify certain motor parameters during runtime. \n",
    "\n",
    "GEM callbacks can be used to interact with the motor environment:\n",
    "- At the start/end of every step\n",
    "- At the start/end of every reset\n",
    "- At the start of a close() call\n",
    "    \n",
    "The following example provides a sample user defined callback implementation. \n",
    "The user defined callback object must be a sub-class of the 'Callback' class as shown. \n",
    "The objective of the user defined 'RewardLogger' callback object is to create a log of the experiment's mean episode rewards.\n",
    "\n",
    "Some of the interfaces implemented here are:\n",
    "- \\__init()\\__     : A suitable class constructor.\n",
    "- on_step_end()    : A suitable task to be performed at the end of every step.\n",
    "- on_reset_begin() : A suitable task at the beginning of each episode.\n",
    "- on_close         : A suitable task at the beginning of a close.\n",
    "\n",
    "For the list of all the interfaces, check out the GEM API documentation.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_electric_motor.core import Callback\n",
    "from pathlib import Path\n",
    "\n",
    "class RewardLogger(Callback):\n",
    "    \"\"\"Logs the reward accumulated in each episode\"\"\"\n",
    "    def __init__(self):\n",
    "        self._step_rewards = []\n",
    "        self._mean_episode_rewards = []\n",
    "        self.fpath = Path.cwd() /\"rl_frameworks\" / \"saved_agents\"\n",
    "        self.fpath.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    def on_step_end(self):\n",
    "        \"\"\"Stores the received reward at each step\"\"\"\n",
    "        self._step_rewards.append(self._env._reward)\n",
    "    \n",
    "    def on_reset_begin(self):\n",
    "        \"\"\"Stores the mean reward received in every episode\"\"\"\n",
    "        self._mean_episode_rewards.append(np.mean(self._step_rewards))\n",
    "        self._step_rewards = []\n",
    "        \n",
    "    def on_close(self):\n",
    "        \"\"\"Writes the mean episode reward of the experiment to a file.\"\"\"\n",
    "        np.save(self.fpath / \"EpisodeRewards.npy\", np.array(self._mean_episode_rewards))\n",
    "        \n",
    "my_callback = [RewardLogger()]  # instantiate the callback object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 GEM Make Call\n",
    "\n",
    "The make function takes the environment-ids and several constructor arguments. Every environment also works without further parameters with default values. These default parameters can be looked up in the [API-documentation](https://upb-lea.github.io/gym-electric-motor/index.html) of every GEM-environment.\n",
    "\n",
    "The various components of the motor environment defined above are passed as arguements to the ```gem.make()``` function. This further returns the discrete PMSM motor environment.\n",
    "\n",
    "The motor environment can then be passed to a Reinforcement Learning agent in order to learn a controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a PMSM with discrete action space\n",
    "env = gem.make(  \n",
    "    motor_env_id,\n",
    "    # visualize the results\n",
    "    visualization=visualization,\n",
    "    # parameterize the PMSM and update limitations\n",
    "    motor_parameter=motor_parameter,\n",
    "    limit_values=limit_values, nominal_values=nominal_values,\n",
    "    # define the random initialisation for load and motor\n",
    "    load=load,\n",
    "    load_initializer=load_initializer,\n",
    "    motor_initializer=motor_initializer,\n",
    "    reward_function=gem.reward_functions.WeightedSumOfErrors(  # The function that computes the reward\n",
    "                observed_states=['i_sq', 'i_sd'],              # Names of the observed states\n",
    "                reward_weights={'i_sq': 10, 'i_sd': 10},       # Reward power for each of the systems states.\n",
    "                constraint_monitor=monitor_sqd_currents,        # ConstraintMonitor for monitoring\n",
    "                                                               # states regarding defined constraints\n",
    "                gamma=gamma,    # Discount factor for the reward punishment. Should equal agent's \n",
    "                                # discount factor gamma.\n",
    "                reward_power=1), # Reward power for each of the systems states\n",
    "    tau=tau,\n",
    "    supply = supply,\n",
    "    supply_parameter=supply_parameter,\n",
    "    reference_generator=rg,\n",
    "    ode_solver='euler',\n",
    "    callbacks = my_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated in episode 980\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# simple routine with random actions applied\n",
    "env.reset()\n",
    "for i in range(1000):\n",
    "    \n",
    "    (states, refs), rewards, done, _ = env.step(env.action_space.sample())  # pick random control actions\n",
    "    env.render()  # visualize environment\n",
    "    if done:\n",
    "        print('Terminated in episode', i)\n",
    "        break\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
